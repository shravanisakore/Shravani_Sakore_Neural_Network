{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Name:-Shravani Sakore\n",
        "\n",
        "\n",
        "\n",
        "PRN:-202201060025\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Batch:-T3"
      ],
      "metadata": {
        "id": "6hgJN--MHlZo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Detailed Comments Explanation:\n",
        "\n",
        "Sigmoid and Derivative:\n",
        "\n",
        "sigmoid(x) computes the output of the sigmoid activation function. It maps any real-valued input into a value between 0 and 1. sigmoid_derivative(x) is the derivative of the sigmoid function, which is used during backpropagation to calculate gradients. Neural Network Class:\n",
        "\n",
        "The NeuralNetwork class contains the methods to initialize the network, perform the forward and backward passes, and train the network. Forward Pass:\n",
        "\n",
        "The forward pass computes the activations of the neurons in the network. The input is passed through the layers, with the weights and biases applied, followed by the activation function (sigmoid) to compute the output. Backward Pass (Backpropagation):\n",
        "\n",
        "During the backward pass, the weights are updated by calculating the error between the predicted output and the true output. The gradients are calculated using the derivative of the sigmoid function, and the weights and biases are updated using gradient descent with a specified learning rate. Training Method:\n",
        "\n",
        "The network is trained by performing multiple epochs, where each epoch involves a forward pass followed by a backward pass. Every 1000 epochs, the loss (mean squared error) is printed to track the network's progress in learning. Main Program:\n",
        "\n",
        "The main program defines a simple XOR dataset, where the inputs are 0 and 1 combinations, and the output is their XOR result. The network is created with 2 input neurons, 4 hidden neurons, and 1 output neuron. The network is trained on the XOR data for 10,000 epochs with a learning rate of 0.1. Output:\n",
        "\n",
        "After training, the network is tested on the same XOR inputs, and the predictions are printed."
      ],
      "metadata": {
        "id": "9SflqUYEHD-h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Sigmoid Activation Function\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "# Derivative of Sigmoid Activation Function\n",
        "def sigmoid_derivative(x):\n",
        "    return x * (1 - x)\n",
        "\n",
        "# Neural Network Class Definition\n",
        "class NeuralNetwork:\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "\n",
        "        # Initialize weights and biases with random values\n",
        "        self.weights_input_hidden = np.random.randn(self.input_size, self.hidden_size)\n",
        "        self.bias_hidden = np.random.randn(1, self.hidden_size)\n",
        "\n",
        "        self.weights_hidden_output = np.random.randn(self.hidden_size, self.output_size)\n",
        "        self.bias_output = np.random.randn(1, self.output_size)\n",
        "\n",
        "    def forward(self, X):\n",
        "        self.input_layer = X\n",
        "        self.hidden_layer_input = np.dot(self.input_layer, self.weights_input_hidden) + self.bias_hidden\n",
        "        self.hidden_layer_output = sigmoid(self.hidden_layer_input)\n",
        "\n",
        "        self.output_layer_input = np.dot(self.hidden_layer_output, self.weights_hidden_output) + self.bias_output\n",
        "        self.output_layer_output = sigmoid(self.output_layer_input)\n",
        "\n",
        "        return self.output_layer_output\n",
        "\n",
        "    def backward(self, X, y, learning_rate):\n",
        "        error_output = y - self.output_layer_output\n",
        "        output_layer_delta = error_output * sigmoid_derivative(self.output_layer_output)\n",
        "\n",
        "        error_hidden = output_layer_delta.dot(self.weights_hidden_output.T)\n",
        "        hidden_layer_delta = error_hidden * sigmoid_derivative(self.hidden_layer_output)\n",
        "\n",
        "        # Update weights and biases\n",
        "        self.weights_hidden_output += self.hidden_layer_output.T.dot(output_layer_delta) * learning_rate\n",
        "        self.bias_output += np.sum(output_layer_delta, axis=0, keepdims=True) * learning_rate\n",
        "\n",
        "        self.weights_input_hidden += X.T.dot(hidden_layer_delta) * learning_rate\n",
        "        self.bias_hidden += np.sum(hidden_layer_delta, axis=0, keepdims=True) * learning_rate\n",
        "\n",
        "    def train(self, X, y, epochs, learning_rate):\n",
        "        for epoch in range(epochs):\n",
        "            self.forward(X)\n",
        "            self.backward(X, y, learning_rate)\n",
        "\n",
        "            if epoch % 1000 == 0:\n",
        "                loss = np.mean(np.square(y - self.output_layer_output))  # Mean squared error\n",
        "                print(f\"Epoch {epoch} - Loss: {loss}\")\n",
        "\n",
        "# Main Program\n",
        "if __name__ == \"__main__\":\n",
        "    # Take user input for the network configuration\n",
        "    input_size = int(input(\"Enter the number of input features: \"))\n",
        "    hidden_size = int(input(\"Enter the number of hidden neurons: \"))\n",
        "    output_size = int(input(\"Enter the number of output neurons: \"))\n",
        "\n",
        "    # Use XOR dataset for testing (2 inputs, 1 output)\n",
        "    X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])  # Input data (XOR inputs)\n",
        "    y = np.array([[0], [1], [1], [0]])  # Expected output data (XOR outputs)\n",
        "\n",
        "    # Ensure input_size matches the dataset's number of features\n",
        "    if X.shape[1] != input_size:\n",
        "        print(f\"Error: The input size should match the number of features in the dataset (currently {X.shape[1]} features).\")\n",
        "        exit()\n",
        "\n",
        "    # Create the neural network with the user-defined configuration\n",
        "    nn = NeuralNetwork(input_size=input_size, hidden_size=hidden_size, output_size=output_size)\n",
        "\n",
        "    # Train the network for 10,000 epochs with a learning rate of 0.1\n",
        "    nn.train(X, y, epochs=10000, learning_rate=0.1)\n",
        "\n",
        "    # After training, print the final predictions of the network\n",
        "    print(\"\\nPredictions after training:\")\n",
        "    print(nn.forward(X))  # Test the network on the XOR inputs\n",
        "\n",
        "    # Allow the user to test the trained model with custom inputs\n",
        "    print(\"\\nEnter new inputs to test the model (type 'exit' to quit):\")\n",
        "    while True:\n",
        "        user_input = input(f\"Input {input_size} comma-separated values: \").strip()\n",
        "        if user_input.lower() == \"exit\":\n",
        "            print(\"Exiting...\")\n",
        "            break\n",
        "        try:\n",
        "            user_data = np.array([list(map(float, user_input.split(\",\")))])\n",
        "            if user_data.shape[1] != input_size:\n",
        "                print(f\"Error: Please enter exactly {input_size} values!\")\n",
        "                continue\n",
        "            prediction = nn.forward(user_data)\n",
        "            print(f\"Model Output: {prediction}\")\n",
        "        except ValueError:\n",
        "            print(\"Invalid input. Please enter numerical values separated by commas.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HsTRogpsHFaa",
        "outputId": "bafabdd2-f65d-46ee-91b3-dd15d7329e44"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the number of input features: 2\n",
            "Enter the number of hidden neurons: 3\n",
            "Enter the number of output neurons: 1\n",
            "Epoch 0 - Loss: 0.2798505383138119\n",
            "Epoch 1000 - Loss: 0.2232275600140935\n",
            "Epoch 2000 - Loss: 0.15939504444495886\n",
            "Epoch 3000 - Loss: 0.06488892546340477\n",
            "Epoch 4000 - Loss: 0.021878375801692468\n",
            "Epoch 5000 - Loss: 0.010984781157480878\n",
            "Epoch 6000 - Loss: 0.006932207241692011\n",
            "Epoch 7000 - Loss: 0.004945973592335246\n",
            "Epoch 8000 - Loss: 0.003798298599841221\n",
            "Epoch 9000 - Loss: 0.0030612845637108524\n",
            "\n",
            "Predictions after training:\n",
            "[[0.0254238 ]\n",
            " [0.95216785]\n",
            " [0.95172358]\n",
            " [0.07031613]]\n",
            "\n",
            "Enter new inputs to test the model (type 'exit' to quit):\n",
            "Input 2 comma-separated values: 0,1\n",
            "Model Output: [[0.95216785]]\n",
            "Input 2 comma-separated values: 0,5\n",
            "Model Output: [[0.97971824]]\n",
            "Input 2 comma-separated values: 0,3\n",
            "Model Output: [[0.97965615]]\n",
            "Input 2 comma-separated values: exit\n",
            "Exiting...\n"
          ]
        }
      ]
    }
  ]
}